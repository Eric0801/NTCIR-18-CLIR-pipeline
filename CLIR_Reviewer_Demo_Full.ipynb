{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1743104e",
   "metadata": {},
   "source": [
    "## Step 0: Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ae35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install transformers rank_bm25 sentence-transformers faiss-cpu jieba tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abff5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 setup_models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00332849",
   "metadata": {},
   "source": [
    "## Step 1: Intialize Models\n",
    "\n",
    "if models haven't installed, it will check and install to \"models/\" directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d24587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Initialize Models (Colab Local)\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "\n",
    "def download_model(name, hf_id, is_classifier=True):\n",
    "    save_dir = Path(\"models\") / name\n",
    "    if save_dir.exists() and any(save_dir.iterdir()):\n",
    "        print(f\"[‚úì] {name} already exists, skipping download.\")\n",
    "        return\n",
    "    print(f\"‚Üì Downloading {name} from HuggingFace...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(hf_id)\n",
    "    model_cls = AutoModelForSequenceClassification if is_classifier else AutoModel\n",
    "    model = model_cls.from_pretrained(hf_id)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tokenizer.save_pretrained(save_dir)\n",
    "    model.save_pretrained(save_dir)\n",
    "    print(f\"[‚úì] {name} saved to {save_dir}\")\n",
    "\n",
    "download_model(\"zhbert\", \"hfl/chinese-roberta-wwm-ext\", is_classifier=True)\n",
    "download_model(\"labse\", \"sentence-transformers/LaBSE\", is_classifier=False)\n",
    "download_model(\"cross_encoder\", \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\", is_classifier=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89ab939",
   "metadata": {},
   "source": [
    "## Step 2: Extract Paragraphs from PDF (PyMuPDF + EasyOCR fallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a4e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import fitz\n",
    "import easyocr\n",
    "import json\n",
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "reader = easyocr.Reader(['ch_tra', 'en'], gpu=False)\n",
    "\n",
    "def extract_blocks_with_heuristics(pdf_path, min_block_length=40):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    results = []\n",
    "    doc_id = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    for page_num, page in enumerate(doc):\n",
    "        blocks = page.get_text(\"blocks\")\n",
    "        for i, block in enumerate(sorted(blocks, key=lambda b: b[1])):\n",
    "            x0, y0, x1, y1, text, *_ = block\n",
    "            clean_text = text.strip().replace(\"\\n\", \" \")\n",
    "            if len(clean_text) >= min_block_length:\n",
    "                results.append({\n",
    "                    \"pid\": f\"{doc_id}_p{page_num}_b{i}\",\n",
    "                    \"page\": page_num,\n",
    "                    \"bbox\": [x0, y0, x1, y1],\n",
    "                    \"text\": clean_text\n",
    "                })\n",
    "    return results\n",
    "\n",
    "def fallback_ocr_easyocr(pdf_path):\n",
    "    images = convert_from_path(pdf_path, dpi=300)\n",
    "    results = []\n",
    "    doc_id = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    for page_num, image in enumerate(images):\n",
    "        ocr_result = reader.readtext(image)\n",
    "        full_text = \" \".join([res[1] for res in ocr_result if len(res[1].strip()) > 0])\n",
    "        if full_text.strip():\n",
    "            results.append({\n",
    "                \"pid\": f\"{doc_id}_ocr_{page_num}\",\n",
    "                \"page\": page_num,\n",
    "                \"bbox\": None,\n",
    "                \"text\": full_text.strip()\n",
    "            })\n",
    "    return results\n",
    "\n",
    "def process_pdf_file(pdf_path):\n",
    "    try:\n",
    "        segments = extract_blocks_with_heuristics(pdf_path)\n",
    "        if not segments or all(len(seg['text']) < 40 for seg in segments):\n",
    "            raise ValueError(\"Fallback to OCR due to poor extraction.\")\n",
    "        return segments\n",
    "    except:\n",
    "        return fallback_ocr_easyocr(pdf_path)\n",
    "\n",
    "pdf_path = \"example.pdf\"\n",
    "results = process_pdf_file(pdf_path)\n",
    "with open(\"clir_pipeline/outputs/structured_passages.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for r in results:\n",
    "        json.dump(r, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")\n",
    "print(\"‚úÖ Done extracting passages.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93703d3",
   "metadata": {},
   "source": [
    "## Step 3: GPT Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce7643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üåê Step 3: GPT-based Batch Translation with Safety Check\n",
    "import openai\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "openai.api_key = \"your-api-key-here\"  # ÊõøÊèõÊàê‰Ω†ÁöÑ GPT API key\n",
    "\n",
    "#ËºâÂÖ•Êü•Ë©¢Ë≥áÊñô \n",
    "\"\"\"Ë∑ØÂæëË¶ÅË™øÊï¥\"\"\"\n",
    "with open(\"/content/questions_translated_en_fixed_q1.json\", \"r\", encoding=\"utf-8\") as f: \n",
    "    full_queries = json.load(f)\n",
    "\n",
    "# GPT ÁøªË≠ØÂáΩÂºèÔºàÁï•ÈÅé placeholderÔºâ\n",
    "def translate_with_gpt(query_en, model=\"gpt-3.5-turbo\"):\n",
    "    if \"EN Translation of:\" in query_en:\n",
    "        return query_en  # Ë¶ñÁÇ∫Êú™ËôïÁêÜÊàñ placeholder\n",
    "    try:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a professional translator who translates English financial search queries into Traditional Chinese.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Translate this search query into Traditional Chinese: '{query_en}'\"}\n",
    "        ]\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0,\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error translating: {query_en} -> {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Âü∑Ë°åÁøªË≠Ø\n",
    "translated_output = []\n",
    "for item in tqdm(full_queries):\n",
    "    zh = translate_with_gpt(item[\"query_en\"])\n",
    "    item[\"query_zh_gpt\"] = zh\n",
    "    translated_output.append(item)\n",
    "\n",
    "# Ëº∏Âá∫ÁøªË≠ØÊ™î\n",
    "with open(\"/content/translated_queries_gpt.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(translated_output, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"‚úÖ GPT ÁøªË≠ØÂÆåÊàêÔºåÂÖ±ËôïÁêÜ %d Á≠ÜÊü•Ë©¢„ÄÇ\" % len(translated_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f3a05c",
   "metadata": {},
   "source": [
    "## Step 4: Run Retrieval (4 Models with Runtime Logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec4f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from run_all_retrievals import run_all_retrievals\n",
    "run_all_retrievals()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad503e56",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate Retrieval Results (Top-K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdcd8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from evaluation_summary import evaluate_all_models\n",
    "import pandas as pd\n",
    "\n",
    "K_values = [10, 100]\n",
    "csv_rows = []\n",
    "\n",
    "for k in K_values:\n",
    "    df = evaluate_all_models(\n",
    "        ranking_path=\"outputs/retrieval_rankings.json\",\n",
    "        ground_truth_path=\"data/ground_truths_example.json\",\n",
    "        output_csv_path=f\"outputs/evaluation_summary_k{k}.csv\",\n",
    "        k=k\n",
    "    )\n",
    "    df[\"TopK\"] = k\n",
    "    csv_rows.append(df)\n",
    "\n",
    "final_df = pd.concat(csv_rows)\n",
    "final_df.to_csv(\"outputs/evaluation_summary_all.csv\", index=False)\n",
    "final_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73572e32",
   "metadata": {},
   "source": [
    "## Step 6: Translation Error Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022e41cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from translate_error_analysis import extract_translation_impact\n",
    "\n",
    "impact = extract_translation_impact(\n",
    "    queries_path=\"data/translated_query.json\",\n",
    "    predictions_path=\"outputs/retrieval_rankings.json\",\n",
    "    ground_truth_path=\"data/ground_truths_example.json\"\n",
    ")\n",
    "\n",
    "for category, group in impact.items():\n",
    "    print(f\"\\n== {category.upper()} ({len(group)} samples) ==\")\n",
    "    for qid, en, zh, pred, gt in group[:1]:\n",
    "        print(f\"QID: {qid}\\nEN: {en}\\nZH: {zh}\\nPRED: {pred}\\nGT: {gt}\\n---\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
