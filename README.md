# ğŸ“˜ Cross-Lingual IR for Traditional Chinese Financial Documents

This is the official demo package for our NTCIR-18 AI Cup submission:

> **"Translation or Multilingual Retrieval? Evaluating Cross-Lingual Search Strategies for Traditional Chinese Financial Documents"**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ‘¨â€ğŸ’» Author

This pipeline and architecture was built by [Yi-Ting, Chiu](https://github.com/Eric0801) (GitHub: [@Eric0801](https://github.com/Eric0801), also known as EatingChew). Any other repository implementing similar functionality is a descendant of this project.

## ğŸ”‘ Model and Dataset Access

Our fine-tuned Chinese-RoBERTa-wwm-ext reranker model is available on HuggingFace. The model, HF token, and dataset are available upon request for:
- ğŸ“ Educational purposes
- ğŸ”¬ Research use
- ğŸ¯ Demo testing

âš ï¸ **Important Notice**: Commercial use of the dataset or pipeline is strictly forbidden. This includes but is not limited to:
- ğŸš« Commercial product development
- ğŸš« Paid services
- ğŸš« Commercial research
- ğŸš« Any for-profit activities

To request access, you can either:

1. **Open an issue in this repository:**
   - Specify your intended use case
   - Provide your institutional email (if applicable)
   - Confirm that your use case is non-commercial

2. **Contact the owner directly:**
   - ğŸ“§ Email: [ericchiu801@gmail.com](mailto:ericchiu801@gmail.com)
   - ğŸ’¼ LinkedIn: [Yi-Ting, Chiu](https://www.linkedin.com/in/é€¸åº­-é‚±/)

We aim to support the research community while ensuring responsible use of our resources.

## ğŸ”’ Security and Privacy Guidelines

When using or forking this project, please ensure you do NOT share:

1. **API Keys and Tokens:**
   - ğŸš« HuggingFace API tokens
   - ğŸš« OpenAI API keys
   - ğŸš« Any other service API credentials

2. **Environment Variables:**
   - ğŸš« `.env` files
   - ğŸš« Configuration files containing sensitive data
   - ğŸš« Local path configurations

3. **Model Weights and Data:**
   - ğŸš« Fine-tuned model weights
   - ğŸš« Training datasets
   - ğŸš« Evaluation datasets
   - ğŸš« Any proprietary data

4. **Personal Information:**
   - ğŸš« User data
   - ğŸš« Personal identifiers
   - ğŸš« Contact information (except for the owner's public contact)

5. **System Information:**
   - ğŸš« Server configurations
   - ğŸš« Database credentials
   - ğŸš« Network settings

Instead, use:
- âœ… Environment variables for sensitive data
- âœ… `.gitignore` to exclude sensitive files
- âœ… Public documentation for setup instructions
- âœ… Sample configuration files with placeholder values

---

## ğŸ“¦ Folder Structure

```
NTCIR-18-CLIR-pipeline/
â”‚
â”œâ”€â”€ CLIR_Reviewer_Demo_Full.ipynb      # Main workflow Jupyter Notebook
â”œâ”€â”€ config.py                          # Path and environment auto-detection settings
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ run_all.sh                         # One-click pipeline shell script
â”œâ”€â”€ run_all_retrievals.py              # Run all retrieval modules
â”œâ”€â”€ setup_models.py                    # Script to download/setup models
â”œâ”€â”€ upload_models.py                   # Script to upload models to HuggingFace
â”œâ”€â”€ QRcode.py                          # QR code generation utility
â”‚
â”œâ”€â”€ data/                              # Query, annotation, and dictionary files
â”‚   â”œâ”€â”€ translated_query.json
â”‚   â”œâ”€â”€ ground_truths_example.json
â”‚   â”œâ”€â”€ userdict.txt
â”‚   â””â”€â”€ pid_map_content.json
â”‚
â”œâ”€â”€ models/                            # Local model storage (should be .gitignored)
â”‚   â”œâ”€â”€ zhbert_finetuned-v2/
â”‚   â”œâ”€â”€ zhbert-finetuned-v2/
â”‚   â””â”€â”€ labse/
â”‚
â”œâ”€â”€ outputs/                           # Output results and intermediate files
â”‚   â”œâ”€â”€ structured_passages.jsonl
â”‚   â””â”€â”€ runs/
â”‚       â””â”€â”€ retrieval_rankings.json
â”‚
â”œâ”€â”€ pdfs/                              # Original PDF files
â”‚   â”œâ”€â”€ finance/
â”‚   â”œâ”€â”€ insurance/
â”‚   â””â”€â”€ faq/
â”‚
â”œâ”€â”€ src/                               # Main source code
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â””â”€â”€ translate_error_analysis.py
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ evaluation.py
â”‚   â”‚   â””â”€â”€ evaluation_summary.py
â”‚   â”œâ”€â”€ preprocess/
â”‚   â”‚   â””â”€â”€ translate.py
â”‚   â”œâ”€â”€ reranker/
â”‚   â”‚   â”œâ”€â”€ bm25_finetune_reranker_dualquery.py
â”‚   â”‚   â”œâ”€â”€ cross_encoder_multilingual.py
â”‚   â”‚   â”œâ”€â”€ fine_tune_reranker.py
â”‚   â”‚   â”œâ”€â”€ fine_tune_reranker_v2.py
â”‚   â”‚   â””â”€â”€ reranker_zhbert_dualquery.py
â”‚   â””â”€â”€ retrievers/
â”‚       â”œâ”€â”€ bm25_only_dualquery.py
â”‚       â””â”€â”€ dual_encoder_dense.py
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## ğŸŒ Environment Support

The pipeline supports multiple environments:
- ğŸ–¥ï¸ Local development
- â˜ï¸ Google Colab
- ğŸ“Š Kaggle

The system automatically detects the environment and adjusts paths and configurations accordingly.

### Environment Setup

1. **Local Environment**
   ```bash
   # Create and activate virtual environment
   python -m venv myenv
   source myenv/bin/activate  # Linux/Mac
   # or
   myenv\Scripts\activate  # Windows
   
   # Install dependencies
   pip install -r requirements.txt
   ```

2. **Google Colab**
   ```python
   # Mount Google Drive
   from google.colab import drive
   drive.mount('/content/drive')
   
   # Install dependencies
   !pip install -r requirements.txt
   ```

3. **Kaggle**
   ```python
   # Install dependencies
   !pip install -r requirements.txt
   ```

### Configuration

The `config.py` file manages all paths and settings. It automatically:
- Detects the current environment
- Sets up appropriate paths
- Handles environment-specific requirements
- Provides error messages specific to each environment

---

## ğŸš€ How to Run

```python
# Step 0: Download models (only first time)
!python setup_models.py

# Step 1: Run 4 retrieval models and generate `.jsonl` results
from run_all_retrievals import run_all_retrievals
run_all_retrievals()

# Step 2: Evaluate
from evaluation_summary import evaluate_all_models

# Step 3: Analyze translation impact
from translate_error_analysis import extract_translation_impact
```

### Running Individual Components

```bash
# Run all retrievals
python run_all_retrievals.py

# Run debug pipeline
python run_all_debug.py

# Generate QR code
python QRcode.py
```

---

## ğŸ“Š Evaluated Metrics

- MRR@10 / NDCG@10 / Recall@100
- Runtime (logged per model)
- Translation error sensitivity analysis

---

## âœï¸ Reviewer's Comments Addressed

- âœ… BM25 baseline added
- âœ… Runtime comparison included
- âœ… Cross-encoder added
- âœ… System flowchart (available in `assets/`)
- âœ… Translation error cases analyzed
- âœ… Citation style fixed
- âœ… Team name removed in paper
- âœ… Multi-environment support added
- âœ… Centralized configuration system
- âœ… Improved error handling and logging

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

The MIT License is a permissive license that is short and to the point. It lets people do anything they want with your code as long as they provide attribution back to you and don't hold you liable.

Key features of the MIT License:
- âœ… Commercial use
- âœ… Modification
- âœ… Distribution
- âœ… Private use
- âœ… Liability limitation
- âœ… Warranty limitation

For more information about the MIT License, visit [opensource.org/licenses/MIT](https://opensource.org/licenses/MIT).

