# ğŸ“˜ Cross-Lingual IR for Traditional Chinese Financial Documents

This is the official demo package for our NTCIR-18 AI Cup submission:

> **"Translation or Multilingual Retrieval? Evaluating Cross-Lingual Search Strategies for Traditional Chinese Financial Documents"**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ‘¨â€ğŸ’» Author

This pipeline and architecture was built by [Yi-Ting, Chiu](https://github.com/Eric0801) (GitHub: [@Eric0801](https://github.com/Eric0801), also known as EatingChew). Any other repository implementing similar functionality is a descendant of this project.

## ğŸ‘¥ Contributors

This project also received support from [Zong-Han, Bai] (GitHub: HummerQAQ), who contributed selectively to early-stage discussions, code testing, and translation error analysis verification. While valuable, these contributions do not cover the core design, full implementation, or the NTCIR-18 paper's final revision process.

All contributions are transparently tracked in the GitHub commit and contributor history.

## ğŸ“¦ Model and Dataset Access

- The fine-tuned Chinese-RoBERTa-wwm-ext reranker model is available on HuggingFace.
- **Training and evaluation datasets are NOT publicly available** due to licensing restrictions.
- For educational, research, or demo use, please contact the owner to request access (see below).
- âš ï¸ **Commercial use is strictly prohibited.**

You may still use the provided code and pipeline with your own data, as long as it follows the same format as shown in the `data/` directory.

To request access, you can either:

1. **Open an issue in this repository:**
   - Specify your intended use case
   - Provide your institutional email (if applicable)
   - Confirm that your use case is non-commercial

2. **Contact the owner directly:**
   - ğŸ“§ Email: [ericchiu801@gmail.com](mailto:ericchiu801@gmail.com)
   - ğŸ’¼ LinkedIn: [Yi-Ting, Chiu](https://www.linkedin.com/in/é€¸åº­-é‚±/)

We aim to support the research community while ensuring responsible use of our resources.

## ğŸ”’ Security and Privacy

**Do NOT commit or share:**
- API keys, tokens, or credentials (HuggingFace, OpenAI, etc.)
- `.env` or config files with sensitive data
- Model weights or proprietary datasets
- Personal or user data
- System credentials or server configs

Use:
- Environment variables for secrets
- `.gitignore` to exclude sensitive files
- Sample config files with placeholders
  
Instead, use:
- âœ… Environment variables for sensitive data
- âœ… `.gitignore` to exclude sensitive files
- âœ… Public documentation for setup instructions
- âœ… Sample configuration files with placeholder values

---

## ğŸ“¦ Folder Structure

```
NTCIR-18-CLIR-pipeline/
â”‚
â”œâ”€â”€ CLIR_Reviewer_Demo_Full.ipynb      # Main workflow Jupyter Notebook
â”œâ”€â”€ config.py                          # Path and environment auto-detection settings
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ run_all.sh                         # One-click pipeline shell script
â”œâ”€â”€ run_all_retrievals.py              # Run all retrieval modules
â”œâ”€â”€ setup_models.py                    # Script to download/setup models
â”œâ”€â”€ upload_models.py                   # Script to upload models to HuggingFace
â”œâ”€â”€ QRcode.py                          # QR code generation utility
â”‚
â”œâ”€â”€ data/                              # Query, annotation, and dictionary files
â”‚   â”œâ”€â”€ translated_query.json
â”‚   â”œâ”€â”€ ground_truths_example.json
â”‚   â”œâ”€â”€ userdict.txt
â”‚   â””â”€â”€ pid_map_content.json
â”‚
â”œâ”€â”€ models/                            # Local model storage (should be .gitignored)
â”‚   â”œâ”€â”€ zhbert_finetuned-v2/
â”‚   â”œâ”€â”€ zhbert-finetuned-v2/
â”‚   â””â”€â”€ labse/
â”‚
â”œâ”€â”€ outputs/                           # Output results and intermediate files
â”‚   â”œâ”€â”€ structured_passages.jsonl
â”‚   â””â”€â”€ runs/
â”‚       â””â”€â”€ retrieval_rankings.json
â”‚
â”œâ”€â”€ pdfs/                              # Original PDF files
â”‚   â”œâ”€â”€ finance/
â”‚   â”œâ”€â”€ insurance/
â”‚   â””â”€â”€ faq/
â”‚
â”œâ”€â”€ src/                               # Main source code
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â””â”€â”€ translate_error_analysis.py
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ evaluation.py
â”‚   â”‚   â””â”€â”€ evaluation_summary.py
â”‚   â”œâ”€â”€ preprocess/
â”‚   â”‚   â””â”€â”€ translate.py
â”‚   â”œâ”€â”€ reranker/
â”‚   â”‚   â”œâ”€â”€ bm25_finetune_reranker_dualquery.py
â”‚   â”‚   â”œâ”€â”€ cross_encoder_multilingual.py
â”‚   â”‚   â”œâ”€â”€ fine_tune_reranker.py
â”‚   â”‚   â”œâ”€â”€ fine_tune_reranker_v2.py
â”‚   â”‚   â””â”€â”€ reranker_zhbert_dualquery.py
â”‚   â””â”€â”€ retrievers/
â”‚       â”œâ”€â”€ bm25_only_dualquery.py
â”‚       â””â”€â”€ dual_encoder_dense.py
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## ğŸŒ Environment Support

The pipeline supports multiple environments:
- ğŸ–¥ï¸ Local development
- â˜ï¸ Google Colab
- ğŸ“Š Kaggle

The system automatically detects the environment and adjusts paths and configurations accordingly.

### Environment Setup

1. **Local Environment**
   ```bash
   # Create and activate virtual environment
   python -m venv myenv
   source myenv/bin/activate  # Linux/Mac
   # or
   myenv\Scripts\activate  # Windows
   
   # Install dependencies
   pip install -r requirements.txt
   ```

2. **Google Colab**
   ```python
   # Mount Google Drive
   from google.colab import drive
   drive.mount('/content/drive')
   
   # Install dependencies
   !pip install -r requirements.txt
   ```

3. **Kaggle**
   ```python
   # Install dependencies
   !pip install -r requirements.txt
   ```

### Configuration

The `config.py` file manages all paths and settings. It automatically:
- Detects the current environment
- Sets up appropriate paths
- Handles environment-specific requirements
- Provides error messages specific to each environment

---

## ğŸš€ How to Run

```python
# Step 0: Download models (only first time)
!python setup_models.py

# Step 1: Run 4 retrieval models and generate `.jsonl` results
from run_all_retrievals import run_all_retrievals
run_all_retrievals()

# Step 2: Evaluate
from evaluation_summary import evaluate_all_models

# Step 3: Analyze translation impact
from translate_error_analysis import extract_translation_impact
```

### Running Individual Components

```bash
# Run all retrievals
python run_all_retrievals.py

# Run debug pipeline
python run_all_debug.py

# Generate QR code
python QRcode.py
```

---

## Evaluated Metrics

- MRR@10 / NDCG@10 / Recall@100
- Runtime (logged per model)
- Translation error sensitivity analysis

---

## Reviewer's Comments Addressed

- âœ… BM25 baseline added
- âœ… Runtime comparison included
- âœ… Cross-encoder added
- âœ… System flowchart (available in `assets/`)
- âœ… Translation error cases analyzed
- âœ… Citation style fixed
- âœ… Team name removed in paper
- âœ… Multi-environment support added
- âœ… Centralized configuration system
- âœ… Improved error handling and logging

---

## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

The MIT License allows commercial and private use, modification, and distribution, provided that attribution is given.

